<!-- doc/src/xml/perform.xml -->

 <chapter id="performance-tips">
  <title>Оптимизация производительности</title>

  <indexterm zone="performance-tips"><primary>производительность</primary></indexterm>

  <para>Быстродействие запросов зависит от многих факторов. На некоторые из них могут воздействовать пользователи, а другие являются фундаментальными особенностями системы. В этой главе приводятся полезные советы, которые помогут понять их и оптимизировать производительность <productname>&productname;</productname>.</para>

 <sect1 id="using-explain">
  <title>Использование <command>EXPLAIN</command></title>

   <indexterm zone="using-explain"><primary>EXPLAIN</primary></indexterm>

   <indexterm zone="using-explain"><primary>план запроса</primary></indexterm>

   <para>Выполняя любой полученный запрос, <productname>&productname;</productname> разрабатывает для него <firstterm>план запроса</firstterm>. Выбор правильного плана, соответствующего структуре запроса и характеристикам данным, крайне важен для хорошей производительности, поэтому в системе работает сложный <firstterm>планировщик</firstterm>, задача которого &mdash; подобрать хороший план. Узнать, какой план был выбран для какого-либо запроса, можно с помощью команды <xref linkend="sql-explain"/>. Понимание плана &mdash; это искусство, и чтобы овладеть им, нужен определённый опыт, но этот раздел расскажет о самых простых вещах.</para>

   <para>Приведённые ниже примеры показаны на тестовой базе данных, которая создаётся для выявления регрессий в исходных кодах <productname>PostgreSQL</productname> текущей версии. Для неё предварительно выполняется <command>VACUUM ANALYZE</command>. Вы должны получить похожие результаты, если возьмёте ту же базу данных и проделаете следующие действия, но примерная стоимость и ожидаемое число строк у вас может немного отличаться из-за того, что статистика команды <command>ANALYZE</command> рассчитывается по случайной выборке, а оценки стоимости зависят от конкретной платформы.</para>

   <para>В этих примерах используется текстовый формат вывода <command>EXPLAIN</command>, принятый по умолчанию, как более компактный и удобный для восприятия человеком. Если вывод <command>EXPLAIN</command> нужно передать какой-либо программе для дальнейшего анализа, лучше использовать один из машинно-ориентированных форматов (XML, JSON или YAML).</para>

  <sect2 id="using-explain-basics">
   <title>Азы <command>EXPLAIN</command></title>

   <para>Структура плана запроса представляет собой дерево <firstterm>узлов плана</firstterm>. Узлы на нижнем уровне дерева &mdash; это узлы сканирования, которые возвращают необработанные данные таблицы. Разным типам доступа к таблице соответствуют разные узлы: последовательное сканирование, сканирование индекса и сканирование битовой карты. Источниками строк могут быть не только таблицы, но и например, предложения <literal>VALUES</literal> и функции, возвращающие множества во <literal>FROM</literal>, и они представляются отдельными типами узлов сканирования. Если запрос требует объединения, агрегатных вычислений, сортировки или других операций с исходными строками, над узлами сканирования появляются узлы, обозначающие эти операции. И так как обычно операции могут выполняться разными способами, на этом уровне тоже могут быть узлы разных типов. В выводе команды <command>EXPLAIN</command> для каждого узла в дереве плана отводится одна строка, где показывается базовый тип узла плюс оценка стоимости выполнения данного узла, которую сделал для него планировщик. Если для узла выводятся дополнительные свойства, в вывод могут добавляться дополнительные строки, с отступом от основной информации узла. В самой первой строке (основной строке самого верхнего узла) выводится общая стоимость выполнения для всего плана; именно это значение планировщик старается минимизировать.</para>

   <para>Взгляните на следующий простейший пример, просто иллюстрирующий формат вывода: <screen>
EXPLAIN SELECT * FROM tenk1;

                         QUERY PLAN
-------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..458.00 rows=10000 width=244)
</screen></para>

   <para>Этот запрос не содержит предложения <literal>WHERE</literal>, поэтому он должен просканировать все строки таблицы, так что планировщик выбрал план простого последовательного сканирования. Числа, перечисленные в скобках (слева направо), имеют следующий смысл: <itemizedlist>
     <listitem>
      <para>Приблизительная стоимость запуска. Это время, которое проходит, прежде чем начнётся этап вывода данных, например для сортирующего узла это время сортировки.</para>
     </listitem>

     <listitem>
      <para>Приблизительная общая стоимость. Она вычисляется в предположении, что узел плана выполняется до конца, то есть возвращает все доступные строки. На практике родительский узел может досрочно прекратить чтение строк дочернего (см. приведённый ниже пример с <literal>LIMIT</literal>).</para>
     </listitem>

     <listitem>
      <para>Ожидаемое число строк, которое должен вывести этот узел плана. При этом так же предполагается, что узел выполняется до конца.</para>
     </listitem>

     <listitem>
      <para>Ожидаемый средний размер строк, выводимых этим узлом плана (в байтах).</para>
     </listitem>
    </itemizedlist></para>

   <para>Стоимость может измеряться в произвольных единицах, определяемых параметрами планировщика (см. <xref remap="4" linkend="runtime-config-query-constants"/>). Традиционно единицей стоимости считается операция чтения страницы с диска; то есть <xref remap="4" linkend="guc-seq-page-cost"/> обычно равен <literal>1.0</literal>, а другие параметры задаётся относительно него. Примеры в этом разделе выполняются со стандартными параметрами стоимости.</para>

   <para>Важно понимать, что стоимость узла верхнего уровня включает стоимость всех его потомков. Также важно осознавать, что эта стоимость отражает только те факторы, которые учитывает планировщик. В частности, она не зависит от времени, необходимого для передачи результирующих строк клиенту, хотя оно может составлять значительную часть общего времени выполнения запроса. Тем не менее планировщик игнорирует эту величину, так как он всё равно не сможет изменить её, выбрав другой план. (Мы верим в то, что любой правильный план запроса выдаёт один и тот же набор строк.)</para>

   <para>Значение <literal>rows</literal> здесь имеет особенность &mdash; оно выражает не число строк, обработанных или просканированных узлом плана, а число строк, выданных этим узлом. Часто оно окажется меньше числа просканированных строк в результате применённой к узлу фильтрации по условиям <literal>WHERE</literal>. В идеале, на верхнем уровне это значение будет приблизительно равно числу строк, которое фактически возвращает, изменяет или удаляет запрос.</para>

   <para>Возвращаясь к нашему примеру: <screen>
EXPLAIN SELECT * FROM tenk1;

                         QUERY PLAN
-------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..458.00 rows=10000 width=244)
</screen></para>

   <para>Эти числа получаются очень просто. Выполните: <programlisting>SELECT relpages, reltuples FROM pg_class WHERE relname = 'tenk1';</programlisting> и вы увидите, что <classname>tenk1</classname> содержит 358 страниц диска и 10000 строк. Общая стоимость вычисляется как (число_чтений_диска * <xref linkend="guc-seq-page-cost"/>) + (число_просканированных_строк * <xref linkend="guc-cpu-tuple-cost"/>). По умолчанию, <varname>seq_page_cost</varname> равно 1.0, а <varname>cpu_tuple_cost</varname> &mdash; 0.01, так что приблизительная стоимость запроса равна (358 * 1.0) + (10000 * 0.01) = 458.</para>

   <para>Теперь давайте изменим запрос, добавив в него предложение <literal>WHERE</literal>: <screen>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 7000;

                             QUERY PLAN
------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..483.00 rows=7001 width=244)
   Filter: (unique1 &lt; 7000)
</screen> Заметьте, что в выводе <command>EXPLAIN</command> показано, что условие <literal>WHERE</literal> применено как <quote>фильтр</quote> к узлу плана Seq Scan (Последовательное сканирование). Это означает, что узел плана проверяет это условие для каждого просканированного им узла и выводит только те строки, которые удовлетворяют ему. Предложение <literal>WHERE</literal> повлияло на оценку числа выходных строк. Однако при сканировании потребуется прочитать все 10000 строк, поэтому общая стоимость не уменьшилась. На деле она даже немного увеличилась (на 10000 * <xref linkend="guc-cpu-operator-cost"/>, если быть точными), отражая дополнительное время, которое потребуется процессору на проверку условия <literal>WHERE</literal>.</para>

   <para>Фактическое число строк результата этого запроса будет равно 7000, но значение <literal>rows</literal> даёт только приблизительное значение. Если вы попытаетесь повторить этот эксперимент, вы можете получить немного другую оценку; более того, она может меняться после каждой команды <command>ANALYZE</command>, так как <command>ANALYZE</command> получает статистику по случайной выборке таблицы.</para>

   <para>Теперь давайте сделаем ограничение более избирательным: <screen>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100;

                             QUERY PLAN
--------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=5.07..229.20 rows=101 width=244)
   Recheck Cond: (unique1 &lt; 100)
   -&gt;  Bitmap Index Scan on tenk1_unique1
                                        (cost=0.00..5.01 rows=101 width=0)
         Index Cond: (unique1 &lt; 100)
</screen> В данном случае планировщик решил использовать план из двух этапов: сначала дочерний узел плана просматривает индекс и находит в нём адреса строк, соответствующих условию индекса, а затем верхний узел собственно выбирает эти строки из таблицы. Выбирать строки по отдельности гораздо дороже, чем просто читать их последовательно, но так как читать придётся не все страницы таблицы, это всё равно будет дешевле, чем сканировать всю таблицу. (Использование двух уровней плана объясняется тем, что верхний узел сортирует адреса строк, выбранных из индекса, в физическом порядке, прежде чем читать, чтобы снизить стоимость отдельных чтений. Слово <quote>bitmap</quote> (битовая карта) в имени узла обозначает механизм, выполняющий сортировку.)</para>

   <para>Теперь давайте добавим ещё одно условие в предложение <literal>WHERE</literal>: <screen>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND stringu1 = 'xxx';

                             QUERY PLAN
--------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=5.01..229.40 rows=1 width=244)
   Recheck Cond: (unique1 &lt; 100)
   Filter: (stringu1 = 'xxx'::name)
   -&gt;  Bitmap Index Scan on tenk1_unique1
                                        (cost=0.00..5.04 rows=101 width=0)
         Index Cond: (unique1 &lt; 100)
</screen> Добавленное условие <literal>stringu1 = 'xxx'</literal> уменьшает оценку числа результирующих строк, но не стоимость запроса, так как просматриваться будет тот же набор строк, что и раньше. Заметьте, что условие на <literal>stringu1</literal> не добавляется в качестве условия индекса, так как индекс построен только по столбцу <literal>unique1</literal>. Вместо этого оно применяется как фильтр к строкам, полученным по индексу. В результате стоимость даже немного увеличилась, отражая добавление этой проверки.</para>

   <para>В некоторых случаях планировщик предпочтёт <quote>простой</quote> план сканирования индекса: <screen>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 = 42;

                             QUERY PLAN
---------------------------------------------------------------------------
 Index Scan using tenk1_unique1 on tenk1 (cost=0.29..8.30 rows=1 width=244)
   Index Cond: (unique1 = 42)
</screen> В плане такого типа строки таблицы выбираются в порядке индекса, в результате чего чтение их обходится дороже, но так как их немного, дополнительно сортировать положения строк не стоит. Вы часто будете встречать этот тип плана в запросах, которые выбирают всего одну строку. Также он часто задействуется там, где условие <literal>ORDER BY</literal> соответствует порядку индекса, так как в этих случаях для выполнения <literal>ORDER BY</literal> не требуется дополнительный шаг сортировки.</para>

   <para>Если в таблице есть отдельные индексы по разным столбцам, фигурирующим в <literal>WHERE</literal>, планировщик может выбрать сочетание этих индексов (с AND и OR): <screen>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000;

                                     QUERY PLAN
-------------------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=25.08..60.21 rows=10 width=244)
   Recheck Cond: ((unique1 &lt; 100) AND (unique2 &gt; 9000))
   -&gt;  BitmapAnd  (cost=25.08..25.08 rows=10 width=0)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.04 rows=101 width=0)
               Index Cond: (unique1 &lt; 100)
         -&gt;  Bitmap Index Scan on tenk1_unique2  (cost=0.00..19.78 rows=999 width=0)
               Index Cond: (unique2 &gt; 9000)
</screen> Но для этого потребуется обойти оба индекса, так что это не обязательно будет выгоднее, чем просто просмотреть один индекс, а второе условие обработать как фильтр. Измените диапазон и вы увидите, как это повлияет на план.</para>

   <para>Следующий пример иллюстрирует эффекты <literal>LIMIT</literal>: <screen>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000 LIMIT 2;

                                     QUERY PLAN
-------------------------------------------------------------------------------------
 Limit  (cost=0.29..14.48 rows=2 width=244)
   -&gt;  Index Scan using tenk1_unique2 on tenk1  (cost=0.29..71.27 rows=10 width=244)
         Index Cond: (unique2 &gt; 9000)
         Filter: (unique1 &lt; 100)
</screen></para>

   <para>Это тот же запрос, что и раньше, но добавили мы в него <literal>LIMIT</literal>, чтобы возвращались не все строки, и планировщик решает выполнять запрос по-другому. Заметьте, что общая стоимость и число строк для узла Index Scan рассчитываются в предположении, что он будет выполняться полностью. Однако узел Limit должен остановиться, получив только пятую часть всех строк, так что его стоимость будет составлять одну пятую от вычисленной ранее, и это и будет итоговой оценкой стоимости запроса. С другой стороны, планировщик мог бы просто добавить в предыдущий план узел Limit, но это не избавило бы от затрат на запуск сканирования битовой карты, а значит, общая стоимость была бы выше 25 единиц.</para>

   <para>Давайте попробуем соединить две таблицы по столбцам, которые мы уже использовали: <screen>
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t1.unique2 = t2.unique2;

                                      QUERY PLAN
--------------------------------------------------------------------------------------
 Nested Loop  (cost=4.65..118.62 rows=10 width=488)
   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=4.36..39.47 rows=10 width=244)
         Recheck Cond: (unique1 &lt; 10)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..4.36 rows=10 width=0)
               Index Cond: (unique1 &lt; 10)
   -&gt;  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.29..7.91 rows=1 width=244)
         Index Cond: (unique2 = t1.unique2)
</screen></para>

   <para>В этом плане появляется узел соединения с вложенным циклом, на вход которому поступают данные от двух его потомков, узлов сканирования. Эту структуру плана отражает отступ основных строк его узлов. Первый, или <quote>внешний</quote>, потомок соединения &mdash; узел сканирования битовой карты, похожий на те, что мы видели раньше. Его стоимость и число строк те же, что мы получили бы для запроса <literal>SELECT ... WHERE unique1 &lt; 10</literal>, так как к этому узлу добавлено предложение <literal>WHERE</literal> <literal>unique1 &lt; 10</literal>. Условие <literal>t1.unique2 = t2.unique2</literal> ещё не учитывается, поэтому оно не влияет на число строк узла внешнего сканирования. Узел соединения с вложенным циклом будет выполнять узел <quote>внутреннего</quote> потомка для каждой строки, полученной из внешнего потомка. Значения столбцов из текущей внешней строки могут использоваться во внутреннем сканировании (в данном случае это значение <literal>t1.unique2</literal>), поэтому мы получаем план и стоимость примерно такие, как и раньше для простого запроса <literal>SELECT ... WHERE t2.unique2 = <replaceable>константа</replaceable></literal>. (На самом деле оценочная стоимость немного меньше, в предположении, что при неоднократном сканировании индекса по <literal>t2</literal> положительную роль сыграет кеширование.) В результате стоимость узла цикла складывается из стоимости внешнего сканирования, цены внутреннего сканирования, умноженной на число строк (здесь 10 * 7.87), и небольшой наценки за обработку соединения.</para>

   <para>В этом примере число выходных строк соединения равно произведению чисел строк двух узлов сканирования, но это не всегда будет так, потому что в дополнительных условиях <literal>WHERE</literal> могут упоминаться обе таблицы, так что применить их можно будет только в точке соединения, а не в одном из узлов сканирования. Например: <screen>
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t2.unique2 &lt; 10 AND t1.hundred &lt; t2.hundred;

                                         QUERY PLAN
---------------------------------------------------------------------------------------------
 Nested Loop  (cost=4.65..49.46 rows=33 width=488)
   Join Filter: (t1.hundred &lt; t2.hundred)
   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=4.36..39.47 rows=10 width=244)
         Recheck Cond: (unique1 &lt; 10)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..4.36 rows=10 width=0)
               Index Cond: (unique1 &lt; 10)
   -&gt;  Materialize  (cost=0.29..8.51 rows=10 width=244)
         -&gt;  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.29..8.46 rows=10 width=244)
               Index Cond: (unique2 &lt; 10)
</screen> Условие <literal>t1.hundred &lt; t2.hundred</literal> не может быть проверено в индексе <literal>tenk2_unique2</literal>, поэтому оно применяется в узле соединения. Это уменьшает оценку числа выходных строк, тогда как число строк в узлах сканирования не меняется.</para>

   <para>Заметьте, что здесь планировщик решил <quote>материализовать</quote> внутреннее отношение соединения, поместив поверх него узел плана Materialize (Материализовать). Это значит, что сканирование индекса <literal>t2</literal> будет выполняться только единожды, при том, что узлу вложенного цикла соединения потребуется прочитать данные десять раз, по числу строк во внешнем соединении. Узел Materialize сохраняет считанные данные в памяти, чтобы затем выдать их из памяти на следующих проходах.</para>

   <para>Выполняя внешние соединения, вы можете встретить узлы плана с присоединёнными условиями, как обычными <quote>Filter</quote>, так и <quote>Join Filter</quote> (Фильтр соединения). Условия Join Filter формируются из предложения <literal>ON</literal> для внешнего соединения, так что если строка не удовлетворяет условию Join Filter, она всё же выдаётся как строка, дополненная значениями NULL. Обычное же условие Filter применяется после правил внешнего соединения и поэтому полностью исключает строки. Во внутреннем соединении оба этих фильтра работают одинаково.</para>

   <para>Если немного изменить избирательность запроса, мы можем получить совсем другой план соединения: <screen>
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;

                                        QUERY PLAN
------------------------------------------------------------------------------------------
 Hash Join  (cost=230.47..713.98 rows=101 width=488)
   Hash Cond: (t2.unique2 = t1.unique2)
   -&gt;  Seq Scan on tenk2 t2  (cost=0.00..445.00 rows=10000 width=244)
   -&gt;  Hash  (cost=229.20..229.20 rows=101 width=244)
         -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=5.07..229.20 rows=101 width=244)
               Recheck Cond: (unique1 &lt; 100)
               -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.04 rows=101 width=0)
                     Index Cond: (unique1 &lt; 100)
</screen></para>

   <para>Здесь планировщик выбирает соединение по хешу, при котором строки одной таблицы записываются в хеш-таблицу в памяти, после чего сканируется другая таблица и для каждой её строки проверяется соответствие по хеш-таблице. Обратите внимание, что и здесь отступы отражают структуру плана: результат сканирования битовой карты по <literal>tenk1</literal> подаётся на вход узлу Hash, который конструирует хеш-таблицу. Затем она передаётся узлу Hash Join, который читает строки из узла внешнего потомка и проверяет их по этой хеш-таблице.</para>

   <para>Ещё один возможный тип соединения &mdash; соединение слиянием: <screen>
EXPLAIN SELECT *
FROM tenk1 t1, onek t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;

                                        QUERY PLAN
------------------------------------------------------------------------------------------
 Merge Join  (cost=198.11..268.19 rows=10 width=488)
   Merge Cond: (t1.unique2 = t2.unique2)
   -&gt;  Index Scan using tenk1_unique2 on tenk1 t1  (cost=0.29..656.28 rows=101 width=244)
         Filter: (unique1 &lt; 100)
   -&gt;  Sort  (cost=197.83..200.33 rows=1000 width=244)
         Sort Key: t2.unique2
         -&gt;  Seq Scan on onek t2  (cost=0.00..148.00 rows=1000 width=244)
</screen></para>

   <para>Соединение слиянием требует, чтобы входные данные для него были отсортированы по ключам соединения. В этом плане данные <literal>tenk1</literal> сортируются после сканирования индекса, при котором все строки просматриваются в правильном порядке, но таблицу <literal>onek</literal> выгоднее оказывается последовательно просканировать и отсортировать, так как в этой таблице нужно обработать гораздо больше строк. (Последовательное сканирование и сортировка часто бывает быстрее сканирования индекса, когда нужно отсортировать много строк, так как при сканировании по индексу обращения к диску не упорядочены.)</para>

   <para>Один из способов посмотреть различные планы &mdash; принудить планировщик не считать выбранную им стратегию самой выгодной, используя флаги, описанные в <xref remap="6" linkend="runtime-config-query-enable"/>. (Это полезный, хотя и грубый инструмент. См. также <xref remap="4" linkend="explicit-joins"/>.) Например, если мы убеждены, что последовательное сканирование и сортировка &mdash; не лучший способ обработать таблицу <literal>onek</literal> в предыдущем примере, мы можем попробовать <screen>
SET enable_sort = off;

EXPLAIN SELECT *
FROM tenk1 t1, onek t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;

                                        QUERY PLAN
------------------------------------------------------------------------------------------
 Merge Join  (cost=0.56..292.65 rows=10 width=488)
   Merge Cond: (t1.unique2 = t2.unique2)
   -&gt;  Index Scan using tenk1_unique2 on tenk1 t1  (cost=0.29..656.28 rows=101 width=244)
         Filter: (unique1 &lt; 100)
   -&gt;  Index Scan using onek_unique2 on onek t2  (cost=0.28..224.79 rows=1000 width=244)
</screen> Видно, что планировщик считает сортировку <literal>onek</literal> со сканированием индекса примерно на 12% дороже, чем последовательное сканирование и сортировку. Конечно, может возникнуть вопрос &mdash; а правильно ли это? Мы можем ответить на него, используя описанную ниже команду <command>EXPLAIN ANALYZE</command>.</para>

  </sect2>

  <sect2 id="using-explain-analyze">
   <title><command>EXPLAIN ANALYZE</command></title>

   <para>Точность оценок планировщика можно проверить, используя команду <command>EXPLAIN</command> с параметром <literal>ANALYZE</literal>. С этим параметром <command>EXPLAIN</command> на самом деле выполняет запрос, а затем выводит фактическое число строк и время выполнения, накопленное в каждом узле плана, вместе с теми же оценками, что выдаёт обычная команда <command>EXPLAIN</command>. Например, мы можем получить примерно такой результат: <screen>
EXPLAIN ANALYZE SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t1.unique2 = t2.unique2;

                                                           QUERY PLAN
---------------------------------------------------------------------------------------------------------------------------------
 Nested Loop  (cost=4.65..118.62 rows=10 width=488) (actual time=0.128..0.377 rows=10 loops=1)
   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=4.36..39.47 rows=10 width=244) (actual time=0.057..0.121 rows=10 loops=1)
         Recheck Cond: (unique1 &lt; 10)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..4.36 rows=10 width=0) (actual time=0.024..0.024 rows=10 loops=1)
               Index Cond: (unique1 &lt; 10)
   -&gt;  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.29..7.91 rows=1 width=244) (actual time=0.021..0.022 rows=1 loops=10)
         Index Cond: (unique2 = t1.unique2)
 Planning time: 0.181 ms
 Execution time: 0.501 ms
</screen> Заметьте, что значения <quote>actual time</quote> (фактическое время) приводятся в миллисекундах, тогда как оценки <literal>cost</literal> (стоимость) выражаются в произвольных единицах, так что они вряд ли совпадут. Обычно важнее определить, насколько приблизительная оценка числа строк близка к действительности. В этом примере они в точности совпали, но на практике так бывает редко.</para>

   <para>В некоторых планах запросов некоторый внутренний узел может выполняться неоднократно. Например, внутреннее сканирование индекса будет выполняться для каждой внешней строки во вложенном цикле верхнего уровня. В таких случаях значение <literal>loops</literal> (циклы) показывает, сколько всего раз выполнялся этот узел, а фактическое время и число строк вычисляется как среднее по всем итерациям. Это делается для того, чтобы полученные значения можно было сравнить с выводимыми приблизительными оценками. Чтобы получить общее время, затраченное на выполнение узла, время одной итерации нужно умножить на значение <literal>loops</literal>. В показанном выше примере мы потратили в общей сложности 0.220 мс на сканирование индекса в <literal>tenk2</literal>.</para>

   <para>В ряде случаев <command>EXPLAIN ANALYZE</command> выводит дополнительную статистику по выполнению, включающую не только время выполнения узлов и число строк. Для узлов Sort и Hash, например выводится следующая информация: <screen>
EXPLAIN ANALYZE SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2 ORDER BY t1.fivethous;

                                                                 QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------------------------
 Sort  (cost=717.34..717.59 rows=101 width=488) (actual time=7.761..7.774 rows=100 loops=1)
   Sort Key: t1.fivethous
   Sort Method: quicksort  Memory: 77kB
   -&gt;  Hash Join  (cost=230.47..713.98 rows=101 width=488) (actual time=0.711..7.427 rows=100 loops=1)
         Hash Cond: (t2.unique2 = t1.unique2)
         -&gt;  Seq Scan on tenk2 t2  (cost=0.00..445.00 rows=10000 width=244) (actual time=0.007..2.583 rows=10000 loops=1)
         -&gt;  Hash  (cost=229.20..229.20 rows=101 width=244) (actual time=0.659..0.659 rows=100 loops=1)
               Buckets: 1024  Batches: 1  Memory Usage: 28kB
               -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=5.07..229.20 rows=101 width=244) (actual time=0.080..0.526 rows=100 loops=1)
                     Recheck Cond: (unique1 &lt; 100)
                     -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.04 rows=101 width=0) (actual time=0.049..0.049 rows=100 loops=1)
                           Index Cond: (unique1 &lt; 100)
 Planning time: 0.194 ms
 Execution time: 8.008 ms
</screen> Для узла Sort показывается использованный метод и место сортировки (в памяти или на диске), а также задействованный объём памяти. Для узла Hash выводится число групп и пакетов хеша, а также максимальный объём, который заняла в памяти хеш-таблица. (Если число пакетов больше одного, часть хеш-таблицы будет выгружаться на диск и занимать какое-то пространство, но его объём здесь не показывается.)</para>

   <para>Другая полезная дополнительная информация &mdash; число строк, удалённых условием фильтра: <screen>
EXPLAIN ANALYZE SELECT * FROM tenk1 WHERE ten &lt; 7;

                                               QUERY PLAN
---------------------------------------------------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..483.00 rows=7000 width=244) (actual time=0.016..5.107 rows=7000 loops=1)
   Filter: (ten &lt; 7)
   Rows Removed by Filter: 3000
 Planning time: 0.083 ms
 Execution time: 5.905 ms
</screen> Эти значения могут быть особенно ценны для условий фильтра, применённых к узлам соединения. Строка <quote>Rows Removed</quote> выводится, только когда условие фильтра отбрасывает минимум одну просканированную строку или потенциальную пару соединения, если это узел соединения.</para>

   <para>Похожую ситуацию можно наблюдать при сканировании <quote>неточного</quote> индекса. Например, рассмотрим этот план поиска многоугольников, содержащих указанную точку: <screen>
EXPLAIN ANALYZE SELECT * FROM polygon_tbl WHERE f1 @&gt; polygon '(0.5,2.0)';

                                              QUERY PLAN
------------------------------------------------------------------------------------------------------
 Seq Scan on polygon_tbl  (cost=0.00..1.05 rows=1 width=32) (actual time=0.044..0.044 rows=0 loops=1)
   Filter: (f1 @&gt; '((0.5,2))'::polygon)
   Rows Removed by Filter: 4
 Planning time: 0.040 ms
 Execution time: 0.083 ms
</screen> Планировщик полагает (и вполне справедливо), что таблица слишком мала для сканирования по индексу, поэтому он выбирает последовательное сканирование, при котором все строки отбрасываются условием фильтра. Но если мы принудим его выбрать сканирование по индексу, мы получим: <screen>
SET enable_seqscan TO off;

EXPLAIN ANALYZE SELECT * FROM polygon_tbl WHERE f1 @&gt; polygon '(0.5,2.0)';

                                                        QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------
 Index Scan using gpolygonind on polygon_tbl  (cost=0.13..8.15 rows=1 width=32) (actual time=0.062..0.062 rows=0 loops=1)
   Index Cond: (f1 @&gt; '((0.5,2))'::polygon)
   Rows Removed by Index Recheck: 1
 Planning time: 0.034 ms
 Execution time: 0.144 ms
</screen> Здесь мы видим, что индекс вернул одну потенциально подходящую строку, но затем она была отброшена при перепроверке условия индекса. Это объясняется тем, что индекс GiST является <quote>неточным</quote> для проверок включений многоугольников: фактически он возвращает строки с многоугольниками, перекрывающими точку по координатам, а затем для этих строк нужно выполнять точную проверку.</para>

   <para><command>EXPLAIN</command> принимает параметр <literal>BUFFERS</literal> (который также можно применять с <literal>ANALYZE</literal>), включающий ещё более подробную статистику выполнения запроса: <screen>
EXPLAIN (ANALYZE, BUFFERS) SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000;

                                                           QUERY PLAN
---------------------------------------------------------------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=25.08..60.21 rows=10 width=244) (actual time=0.323..0.342 rows=10 loops=1)
   Recheck Cond: ((unique1 &lt; 100) AND (unique2 &gt; 9000))
   Buffers: shared hit=15
   -&gt;  BitmapAnd  (cost=25.08..25.08 rows=10 width=0) (actual time=0.309..0.309 rows=0 loops=1)
         Buffers: shared hit=7
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.04 rows=101 width=0) (actual time=0.043..0.043 rows=100 loops=1)
               Index Cond: (unique1 &lt; 100)
               Buffers: shared hit=2
         -&gt;  Bitmap Index Scan on tenk1_unique2  (cost=0.00..19.78 rows=999 width=0) (actual time=0.227..0.227 rows=999 loops=1)
               Index Cond: (unique2 &gt; 9000)
               Buffers: shared hit=5
 Planning time: 0.088 ms
 Execution time: 0.423 ms
</screen> Значения, которые выводятся с параметром <literal>BUFFERS</literal>, помогают понять, на какие части запроса приходится большинство операций ввода-вывода.</para>

   <para>Не забывайте, что <command>EXPLAIN ANALYZE</command> действительно выполняет запрос, хотя его результаты могут не показываться, а заменяться выводом команды <command>EXPLAIN</command>. Поэтому при таком анализе возможны побочные эффекты. Если вы хотите проанализировать запрос, изменяющий данные, но при этом сохранить прежние данные таблицы, вы можете откатить транзакцию после запроса: <screen>
BEGIN;

EXPLAIN ANALYZE UPDATE tenk1 SET hundred = hundred + 1 WHERE unique1 &lt; 100;

                                                           QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------------
 Update on tenk1  (cost=5.07..229.46 rows=101 width=250) (actual time=14.628..14.628 rows=0 loops=1)
   -&gt;  Bitmap Heap Scan on tenk1  (cost=5.07..229.46 rows=101 width=250) (actual time=0.101..0.439 rows=100 loops=1)
         Recheck Cond: (unique1 &lt; 100)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.04 rows=101 width=0) (actual time=0.043..0.043 rows=100 loops=1)
               Index Cond: (unique1 &lt; 100)
 Planning time: 0.079 ms
 Execution time: 14.727 ms

ROLLBACK;
</screen></para>

   <para>Как показано в этом примере, когда выполняется команда <command>INSERT</command>, <command>UPDATE</command> или <command>DELETE</command>, собственно изменение данных в таблице происходит в узле верхнего уровня Insert, Update или Delete. Узлы плана более низких уровней выполняют работу по нахождению старых строк и/или вычислению новых данных. Поэтому вверху мы видим тот же тип сканирования битовой карты, что и раньше, только теперь его вывод подаётся узлу Update, который сохраняет изменённые строки. Стоит отметить, что узел, изменяющий данные, может выполняться значительное время (в данном случае это составляет львиную часть всего времени), но планировщик не учитывает эту работу в оценке общей стоимости. Это связано с тем, что эта работа будет одинаковой при любом правильном плане запроса, и поэтому на выбор плана она не влияет.</para>

   <para>Когда команда <command>UPDATE</command> или <command>DELETE</command> имеет дело с иерархией наследования, вывод может быть таким: <screen>
EXPLAIN UPDATE parent SET f2 = f2 + 1 WHERE f1 = 101;
                                    QUERY PLAN
-----------------------------------------------------------------------------------
 Update on parent  (cost=0.00..24.53 rows=4 width=14)
   Update on parent
   Update on child1
   Update on child2
   Update on child3
   -&gt;  Seq Scan on parent  (cost=0.00..0.00 rows=1 width=14)
         Filter: (f1 = 101)
   -&gt;  Index Scan using child1_f1_key on child1  (cost=0.15..8.17 rows=1 width=14)
         Index Cond: (f1 = 101)
   -&gt;  Index Scan using child2_f1_key on child2  (cost=0.15..8.17 rows=1 width=14)
         Index Cond: (f1 = 101)
   -&gt;  Index Scan using child3_f1_key on child3  (cost=0.15..8.17 rows=1 width=14)
         Index Cond: (f1 = 101)
</screen> В этом примере узлу Update помимо изначально упомянутой в запросе родительской таблицы нужно обработать ещё три дочерние таблицы. Поэтому формируются четыре плана сканирования, по одному для каждой таблицы. Ясности ради для узла Update добавляется примечание, показывающее, какие именно таблицы будут изменяться, в том же порядке, в каком они идут в соответствующих внутренних планах. (Эти примечания появились в <productname>&productname;</productname> 9.5; до этого о целевых таблицах приходилось догадываться, изучая внутренние планы узла.)</para>

   <para>Под заголовком <literal>Planning time</literal> (Время планирования) команда <command>EXPLAIN ANALYZE</command> выводит время, затраченное на построение плана запроса из разобранного запроса и его оптимизацию. Время собственно разбора или перезаписи запроса в него не включается.</para>

   <para>Значение <literal>Execution time</literal> (Время выполнения), выводимое командой <command>EXPLAIN ANALYZE</command>, включает продолжительность запуска и остановки исполнителя запроса, а также время выполнения всех сработавших триггеров, но не включает время разбора, перезаписи и планирования запроса. Время, потраченное на выполнение триггеров <literal>BEFORE</literal> (если такие имеются) включается во время соответствующих узлов Insert, Update или Delete node; но время выполнения триггеров <literal>AFTER</literal> не учитывается, так как триггеры <literal>AFTER</literal> срабатывают после выполнения всего плана. Общее время, проведённое в каждом триггере (<literal>BEFORE</literal> или <literal>AFTER</literal>), также выводится отдельно. Заметьте, что триггеры отложенных ограничений выполняются только в конце транзакции, так что время их выполнения <command>EXPLAIN ANALYZE</command> не учитывает.</para>

  </sect2>

  <sect2 id="using-explain-caveats">
   <title>Ограничения</title>

   <para>Время выполнения, измеренное командой <command>EXPLAIN ANALYZE</command>, может значительно отличаться от времени выполнения того же запроса в обычном режиме. Тому есть две основных причины. Во-первых, так как при анализе никакие строки результата не передаются клиенту, время ввода/вывода и передачи по сети не учитывается. Во-вторых, может быть существенной дополнительная нагрузка, связанная с функциями измерений <command>EXPLAIN ANALYZE</command>, особенно в системах, где вызов <function>gettimeofday()</function> выполняется медленно. Для измерения этой нагрузки вы можете воспользоваться утилитой <xref linkend="pgtesttiming"/>.</para>

   <para>Результаты <command>EXPLAIN</command> не следует распространять на ситуации, значительно отличающиеся от тех, в которых вы проводите тестирование. В частности, не следует полагать, что выводы, полученные для игрушечной таблицы, будут применимы и для настоящих больших таблиц. Оценки стоимости нелинейны и планировщик может выбирать разные планы в зависимости от размера таблицы. Например, в крайнем случае вся таблица может уместиться в одну страницу диска, и тогда вы почти наверняка получите план последовательного сканирования, независимо от того, есть у неё и индексы или нет. Планировщик понимает, что для обработки таблицы ему в любом случае потребуется прочитать одну страницу, так что нет никакого смысла обращаться к ещё одной странице за индексом. (Мы наблюдали это в показанном выше примере с <literal>polygon_tbl</literal>.)</para>

   <para>Бывает, что фактическое и приближённо оценённое значения не совпадают, но в этом нет ничего плохого. Например, это возможно, когда выполнение плана узла прекращается преждевременно из-за указания <literal>LIMIT</literal> или подобного эффекта. Например, для запроса с <literal>LIMIT</literal>, который мы пробовали раньше: <screen>
EXPLAIN ANALYZE SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000 LIMIT 2;

                                                          QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.29..14.71 rows=2 width=244) (actual time=0.177..0.249 rows=2 loops=1)
   -&gt;  Index Scan using tenk1_unique2 on tenk1  (cost=0.29..72.42 rows=10 width=244) (actual time=0.174..0.244 rows=2 loops=1)
         Index Cond: (unique2 &gt; 9000)
         Filter: (unique1 &lt; 100)
         Rows Removed by Filter: 287
 Planning time: 0.096 ms
 Execution time: 0.336 ms
</screen> Оценки стоимости и числа строк для узла Index Scan показываются в предположении, что этот узел будет выполняться до конца. Но в действительности узел Limit прекратил запрашивать строки, как только получил первые две, так что фактическое число строк равно 2 и время выполнения запроса будет меньше, чем рассчитал планировщик. Но это не ошибка, а просто следствие того, что оценённые и фактические значения выводятся по-разному.</para>

   <para>Соединения слиянием также имеют свои особенности, которые могут ввести в заблуждение. Соединение слиянием прекратит читать один источник данных, если второй будет прочитан до конца, а следующее значение ключа в первом больше последнего значения во втором. В этом случае пар строк больше не будет, так что сканировать первый источник дальше нет смысла. В результате будут прочитаны не все строки одного потомка и вы получите тот же эффект, что и с <literal>LIMIT</literal>. Кроме того, если внешний (первый) потомок содержит строки с повторяющимися значениями ключа, внутренний (второй) потомок сдвинется назад и повторно выдаст строки для этого значения ключа. <command>EXPLAIN ANALYZE</command> считает эти повторяющиеся строки, как если бы это действительно были дополнительные строки внутреннего источника. Когда во внешнем узле много таких повторений ключей, фактическое число строк, подсчитанное для внутреннего узла, может значительно превышать число строк в соответствующей таблице.</para>

   <para>Для узлов BitmapAnd (Логическое произведение битовых карт) и BitmapOr (Логическое сложение битовых карт) фактическое число строк всегда равно 0 из-за ограничений реализации.</para>
  </sect2>

 </sect1>

 <sect1 id="planner-stats">
  <title>Статистика, используемая планировщиком</title>

  <indexterm zone="planner-stats"><primary>статистика</primary> <secondary>планировщика</secondary></indexterm>

  <para>Как было показано в предыдущем разделе, планировщик запросов должен оценить число строк, возвращаемых запросов, чтобы сделать правильный выбор в отношении плана запроса. В этом разделе кратко описывается статистика, которую использует система для этих оценок.</para>

  <para>В частности, статистика включает общее число записей в каждой таблице и индексе, а также число дисковых блоков, которые они занимают. Эта информация содержится в таблице <link linkend="catalog-pg-class"><structname>pg_class</structname></link>, в столбцах <structfield>reltuples</structfield> и <structfield>relpages</structfield>. Получить её можно, например так: <screen>
SELECT relname, relkind, reltuples, relpages
FROM pg_class
WHERE relname LIKE 'tenk1%';

       relname        | relkind | reltuples | relpages
----------------------+---------+-----------+----------
 tenk1                | r       |     10000 |      358
 tenk1_hundred        | i       |     10000 |       30
 tenk1_thous_tenthous | i       |     10000 |       30
 tenk1_unique1        | i       |     10000 |       30
 tenk1_unique2        | i       |     10000 |       30
(5 rows)
</screen> Здесь мы видим, что <structname>tenk1</structname> содержит 10000 строк данных и столько же строк в индексах (что неудивительно), но объём индексов гораздо меньше таблицы.</para>

  <para>Для большей эффективности <structfield>reltuples</structfield> и <structfield>relpages</structfield> не пересчитываются &laquo;на лету&raquo;, так что они обычно содержат несколько устаревшие значения. Их обновляют команды <command>VACUUM</command>, <command>ANALYZE</command> и несколько команд DDL, такие как <command>CREATE INDEX</command>. <command>VACUUM</command> и <command>ANALYZE</command> могут не сканировать всю таблицу (и обычно так и делают), а только вычислить приращение <structfield>reltuples</structfield> по части таблицы, так что результат остаётся приблизительным. В любом случае планировщик пересчитывает значения, полученные из <structname>pg_class</structname>, в пропорции к текущему физическому размеру таблицы и таким образом уточняет приближение.</para>

  <indexterm><primary>pg_statistic</primary></indexterm>

  <para>Большинство запросов возвращают не все строки таблицы, а только немногие из них, ограниченные условиями <literal>WHERE</literal>. Поэтому планировщику нужно оценить <firstterm>избирательность</firstterm> условий <literal>WHERE</literal>, то есть определить, какой процент строк будет соответствовать каждому условию в предложении <literal>WHERE</literal>. Нужная для этого информация хранится в системном каталоге <link linkend="catalog-pg-statistic"><structname>pg_statistic</structname></link>. Значения в <structname>pg_statistic</structname> обновляются командами <command>ANALYZE</command> и <command>VACUUM ANALYZE</command> и никогда не бывают точными, даже сразу после обновления.</para>

  <indexterm><primary>pg_stats</primary></indexterm>

  <para>Для исследования статистики лучше обращаться не непосредственно к таблице <structname>pg_statistic</structname>, а к представлению <link linkend="view-pg-stats"><structname>pg_stats</structname></link>, предназначенному для облегчения восприятия этой информации. Кроме того, представление <structname>pg_stats</structname> доступно для чтения всем, тогда как <structname>pg_statistic</structname> &mdash; только суперпользователям. (Это сделано для того, чтобы непривилегированные пользователи не могли ничего узнать о содержимом таблиц других людей из статистики. Представление <structname>pg_stats</structname> устроено так, что оно показывает строки только для тех таблиц, которые может читать данный пользователь.) Например, мы можем выполнить: <screen>
SELECT attname, inherited, n_distinct,
       array_to_string(most_common_vals, E'\n') as most_common_vals
FROM pg_stats
WHERE tablename = 'road';

 attname | inherited | n_distinct |          most_common_vals
---------+-----------+------------+------------------------------------
 name    | f         |  -0.363388 | I- 580                        Ramp+
         |           |            | I- 880                        Ramp+
         |           |            | Sp Railroad                       +
         |           |            | I- 580                            +
         |           |            | I- 680                        Ramp
 name    | t         |  -0.284859 | I- 880                        Ramp+
         |           |            | I- 580                        Ramp+
         |           |            | I- 680                        Ramp+
         |           |            | I- 580                            +
         |           |            | State Hwy 13                  Ramp
(2 rows)
</screen> Заметьте, что для одного столбца показываются две строки: одна соответствует полной иерархии наследования, построенной для таблицы <literal>road</literal> (<literal>inherited</literal>=<literal>t</literal>), и другая относится непосредственно к таблице <literal>road</literal> (<literal>inherited</literal>=<literal>f</literal>).</para>

  <para>Объём информации, сохраняемой в <structname>pg_statistic</structname> командой <command>ANALYZE</command>, в частности максимальное число записей в массивах <structfield>most_common_vals</structfield> (самые популярные значения) и <structfield>histogram_bounds</structfield> (границы гистограмм) для каждого столбца, можно ограничить на уровне столбцов с помощью команды <command>ALTER TABLE SET STATISTICS</command> или глобально, установив параметр конфигурации <xref linkend="guc-default-statistics-target"/>. В настоящее время ограничение по умолчанию равно 100 записям. Увеличивая этот предел, можно увеличить точность оценок планировщика, особенно для столбцов с нерегулярным распределением данных, ценой большего объёма <structname>pg_statistic</structname> и, возможно, увеличения времени расчёта этой статистики. И напротив, для столбцов с простым распределением данных может быть достаточно меньшего предела.</para>

  <para>Подробнее использование статистики планировщиком описывается в <xref remap="6" linkend="planner-stats-details"/>.</para>

 </sect1>

 <sect1 id="explicit-joins">
  <title>Управление планировщиком с помощью явных предложений <literal>JOIN</literal></title>

  <indexterm zone="explicit-joins"><primary>соединение</primary> <secondary>управление порядком</secondary></indexterm>

  <para>Поведением планировщика в некоторой степени можно управлять, используя явный синтаксис <literal>JOIN</literal>. Понять, когда и почему это бывает нужно, поможет небольшое введение.</para>

  <para>В простом запросе с соединением, например таком: <programlisting>SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;</programlisting> планировщик может соединять данные таблицы в любом порядке. Например, он может разработать план, в котором сначала A соединяется с B по условию <literal>WHERE</literal> <literal>a.id = b.id</literal>, а затем C соединяется с получившейся таблицей по другому условию <literal>WHERE</literal>. Либо он может соединить B с C, а затем с A результатом соединения. Он также может соединить сначала A с C, а затем результат с B &mdash; но это будет не эффективно, так как ему придётся сформировать полное декартово произведение A и C из-за отсутствия в предложении <literal>WHERE</literal> условия, подходящего для оптимизации соединения. (В <productname>&productname;</productname> исполнитель запросов может соединять только по две таблицы, поэтому для получения результата нужно выбрать один из этих способов.) При этом важно понимать, что все эти разные способы соединения дают одинаковые по смыслу результаты, но стоимость их может различаться многократно. Поэтому планировщик должен изучить их все и найти самый эффективный способ выполнения запроса.</para>

  <para>Когда запрос включает только две или три таблицы, возможны всего несколько вариантов их соединения. Но их число растёт экспоненциально с увеличением числа задействованных таблиц. Если число таблиц больше десяти, уже практически невозможно выполнить полный перебор всех вариантов, и даже для шести или семи таблиц планирование может занять недопустимо много времени. Когда таблиц слишком много, планировщик <productname>&productname;</productname> переключается с полного поиска на алгоритм <firstterm>генетического</firstterm> вероятностного поиска в ограниченном числе вариантов. (Порог для этого переключения задаётся параметром выполнения <xref linkend="guc-geqo-threshold"/>.) Генетический поиск выполняется быстрее, но не гарантирует, что найденный план будет наилучшим.</para>

  <para>Когда запрос включает внешние соединения, планировщик имеет меньше степеней свободы, чем с обычными (внутренними) соединениями. Например, рассмотрим запрос: <programlisting>SELECT * FROM a LEFT JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);</programlisting> Хотя ограничения в этом запросе очень похожи на показанные в предыдущем примере, смысл его отличается, так как результирующая строка должна выдаваться для каждой строки A, даже если для неё не находится соответствия в соединении B и C. Таким образом, здесь планировщик не может выбирать порядок соединения: он должен соединить B с C, а затем соединить A с результатом. Соответственно, и план этого запроса построится быстрее, чем предыдущего. В других случаях планировщик сможет определить, что можно безопасно выбрать один из нескольких способов соединения. Например, для запроса: <programlisting>SELECT * FROM a LEFT JOIN b ON (a.bid = b.id) LEFT JOIN c ON (a.cid = c.id);</programlisting> можно соединить A либо с B, либо с C. В настоящее время только <literal>FULL JOIN</literal> полностью ограничивает порядок соединения. На практике в большинстве запросов с <literal>LEFT JOIN</literal> и <literal>RIGHT JOIN</literal> порядком можно управлять в некоторой степени.</para>

  <para>Синтаксис явного внутреннего соединения (<literal>INNER JOIN</literal>, <literal>CROSS JOIN</literal> или лаконичный <literal>JOIN</literal>) по смыслу равнозначен перечислению отношений в предложении <literal>FROM</literal>, так что он никак не ограничивает порядок соединений.</para>

  <para>Хотя большинство видов <literal>JOIN</literal> не полностью ограничивают порядок соединения, в <productname>&productname;</productname> можно принудить планировщик обрабатывать все предложения <literal>JOIN</literal> как ограничивающие этот порядок. Например, следующие три запроса логически равнозначны: <programlisting>SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;
SELECT * FROM a CROSS JOIN b CROSS JOIN c WHERE a.id = b.id AND b.ref = c.id;
SELECT * FROM a JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);</programlisting> Но если мы укажем планировщику соблюдать порядок <literal>JOIN</literal>, на планирование второго и третьего уйдёт меньше времени. Когда речь идёт только о трёх таблицах, выигрыш будет незначительным, но для множества таблиц это может быть очень эффективно.</para>

  <para>Чтобы планировщик соблюдал порядок внутреннего соединения, выраженный явно предложениями <literal>JOIN</literal>, нужно присвоить параметру выполнения <xref linkend="guc-join-collapse-limit"/> значение 1. (Другие допустимые значения обсуждаются ниже.)</para>

  <para>Чтобы сократить время поиска, необязательно полностью ограничивать порядок соединений, в <literal>JOIN</literal> можно соединять элементы как в обычном списке <literal>FROM</literal>. Например, рассмотрите следующий запрос: <programlisting>SELECT * FROM a CROSS JOIN b, c, d, e WHERE ...;</programlisting> Если <varname>join_collapse_limit</varname> = 1, планировщик будет вынужден соединить A с B раньше, чем результат с другими таблицами, но в дальнейшем выборе вариантов он не ограничен. В данном примере число возможных вариантов соединения уменьшается в 5 раз.</para>

  <para>Упрощать для планировщика задачу перебора вариантов таким способом &mdash; это полезный приём, помогающий не только выбрать сократить время планирования, но и подтолкнуть планировщик к хорошему плану. Если планировщик по умолчанию выбирает неудачный порядок соединения, вы можете заставить его выбрать лучший, применив синтаксис <literal>JOIN</literal>, конечно если вы сами его знаете. Эффект подобной оптимизации рекомендуется подтверждать экспериментально.</para>

  <para>На время планирования влияет и другой, тесно связанный фактор &mdash; решение о включении подзапросов в родительский запрос. Пример такого запроса: <programlisting>SELECT *
FROM x, y,
    (SELECT * FROM a, b, c WHERE something) AS ss
WHERE somethingelse;</programlisting> Такая же ситуация может возникнуть с представлением, содержащим соединение; вместо ссылки на это представление будет вставлено его выражение <literal>SELECT</literal> и в результате получится запрос, похожий на показанный выше. Обычно планировщик старается включить подзапрос в родительский запрос и получить таким образом: <programlisting>SELECT * FROM x, y, a, b, c WHERE something AND somethingelse;</programlisting> Часто это позволяет построить лучший план, чем при планировании подзапросов по отдельности. (Например, внешние условия <literal>WHERE</literal> могут быть таковы, что при соединении сначала X с A будет исключено множество строк A, а значит формировать логический результат подзапроса полностью не потребуется.) Но в то же время тем самым мы увеличиваем время планирования; две задачи соединения трёх элементов мы заменяем одной с пятью элементами. Так как число вариантов увеличивается экспоненциально, сложность задачи увеличивается многократно. Планировщик пытается избежать проблем поиска с огромным числом вариантов, рассматривая подзапросы отдельно, если в предложении <literal>FROM</literal> родительского запроса оказывается больше чем <varname>from_collapse_limit</varname> элементов. Изменяя этот параметр выполнения, можно подобрать оптимальное соотношение времени планирования и качества плана.</para>

  <para>Параметры <xref linkend="guc-from-collapse-limit"/> и <xref linkend="guc-join-collapse-limit"/> называются похоже, потому что они делают практически одно и то же: первый параметр определяет, когда планировщик будет <quote>сносить</quote> в предложение <literal>FROM</literal> подзапросы, а второй &mdash; явные соединения. Обычно <varname>join_collapse_limit</varname> устанавливается равным <varname>from_collapse_limit</varname> (чтобы явные соединения и подзапросы обрабатывались одинаково) или 1 (если требуется управлять порядком соединений). Но вы можете задать другие значения, чтобы добиться оптимального соотношения времени планирования и времени выполнения запросов.</para>
 </sect1>

 <sect1 id="populate">
  <title>Наполнение базы данных</title>

  <para>Довольно часто в начале или в процессе использования базы данных возникает необходимость загрузить в неё большой объём данных. В этом разделе приведены рекомендации, которые помогут сделать это максимально эффективно.</para>

  <sect2 id="disable-autocommit">
   <title>Отключите автофиксацию транзакций</title>

   <indexterm><primary>автофиксация</primary> <secondary>массовая загрузка данных</secondary></indexterm>

   <para>Выполняя серию команд <command>INSERT</command>, выключите автофиксацию транзакций и зафиксируйте транзакцию только один раз в самом конце. (В обычном SQL это означает, что нужно выполнить <command>BEGIN</command> до, и <command>COMMIT</command> после этой серии. Некоторые клиентские библиотеки могут делать это автоматически, в таких случаях нужно убедиться, что это так.) Если вы будете фиксировать каждое добавление по отдельности, <productname>&productname;</productname> придётся проделать много действий для каждой добавляемой строки. Выполнять все операции в одной транзакции хорошо ещё и потому, что в случае ошибки добавления одной из строк произойдёт откат к исходному состоянию и вы не окажетесь в сложной ситуации с частично загруженными данными.</para>
  </sect2>

  <sect2 id="populate-copy-from">
   <title>Используйте <command>COPY</command></title>

   <para>Используйте <xref linkend="sql-copy"/>, чтобы загрузить все строки одной командой вместо серии <command>INSERT</command>. Команда <command>COPY</command> оптимизирована для загрузки большого количества строк; хотя она не так гибка, как <command>INSERT</command>, но при загрузке больших объёмов данных она влечёт гораздо меньше накладных расходов. Так как <command>COPY</command> &mdash; это одна команда, применяя её, нет необходимости отключать автофиксацию транзакций.</para>

   <para>В случаях, когда <command>COPY</command> не подходит, может быть полезно создать подготовленный оператор <command>INSERT</command> с помощью <xref linkend="sql-prepare"/>, а затем выполнять <command>EXECUTE</command> столько раз, сколько потребуется. Это позволит избежать накладных расходов, связанных с разбором и анализом каждой команды <command>INSERT</command>. В разных интерфейсах это может выглядеть по-разному; за подробностями обратитесь к описанию <quote>подготовленных операторов</quote> в документации конкретного интерфейса.</para>

   <para>Заметьте, что с помощью <command>COPY</command> большое количество строк практически всегда загружается быстрее, чем с помощью <command>INSERT</command>, даже если используется <command>PREPARE</command> и серия операций добавления заключена в одну транзакцию.</para>

   <para><command>COPY</command> работает быстрее всего, если она выполняется в одной транзакции с командами <command>CREATE TABLE</command> или <command>TRUNCATE</command>. В таких случаях записывать WAL не нужно, так как в случае ошибки файлы, содержащие загружаемые данные, будут всё равно удалены. Однако это замечание справедливо, только когда параметр <xref linkend="guc-wal-level"/> равен <literal>minimal</literal>, так как в противном случае все команды должны записывать свои изменения в WAL.</para>

  </sect2>

  <sect2 id="populate-rm-indexes">
   <title>Удалите индексы</title>

   <para>Если вы загружаете данные в только что созданную таблицу, быстрее всего будет загрузить данные с помощью <command>COPY</command>, а затем создать все необходимые для неё индексы. На создание индекса для уже существующих данных уйдёт меньше времени, чем на последовательное его обновление при добавлении каждой строки.</para>

   <para>Если вы добавляете данные в существующую таблицу, может иметь смысл удалить индексы, загрузить таблицу, а затем пересоздать индексы. Конечно, при этом надо учитывать, что временное отсутствие индексов может отрицательно повлиять на скорость работы других пользователей. Кроме того, следует дважды подумать, прежде чем удалять уникальные индексы, так как без них соответствующие проверки ключей не будут выполняться.</para>
  </sect2>

  <sect2 id="populate-rm-fkeys">
   <title>Удалите ограничения внешних ключей</title>

   <para>Как и с индексами, проверки, связанные с ограничениями внешних ключей, выгоднее выполнять <quote>массово</quote>, а не для каждой строки в отдельности. Поэтому может быть полезно удалить ограничения внешних ключей, загрузить данные, а затем восстановить прежние ограничения. И в этом случае тоже приходится выбирать между скоростью загрузки данных и риском допустить ошибки в отсутствие ограничений.</para>

   <para>Более того, когда вы загружаете данные в таблицу с существующими ограничениями внешнего ключа, для каждой новой строки добавляется запись в очередь событий триггера (так как именно срабатывающий триггер проверяет такие ограничения для строки). При загрузке многих миллионов строк очередь событий триггера может занять всю доступную память, что приведёт к недопустимой нагрузке на файл подкачки или даже к сбою команды. Таким образом, загружая большие объёмы данных, может быть не просто желательно, а <emphasis>необходимо</emphasis> удалять, а затем восстанавливать внешние ключи. Если же временное отключение этого ограничения неприемлемо, единственно возможным решением может быть разделение всей операции загрузки на меньшие транзакции.</para>
  </sect2>

  <sect2 id="populate-work-mem">
   <title>Увеличьте <varname>maintenance_work_mem</varname></title>

   <para>Ускорить загрузку больших объёмов данных можно, увеличив параметр конфигурации <xref linkend="guc-maintenance-work-mem"/> на время загрузки. Это приведёт к увеличению быстродействия <command>CREATE INDEX</command> и <command>ALTER TABLE ADD FOREIGN KEY</command>. На скорость самой команды <command>COPY</command> это не повлияет, так что этот совет будет полезен, только если вы применяете какой-либо из двух вышеописанных приёмов.</para>
  </sect2>

  <sect2 id="populate-max-wal-size">
   <title>Увеличьте <varname>max_wal_size</varname></title>

   <para>Также массовую загрузку данных можно ускорить, изменив на время загрузки параметр конфигурации <xref linkend="guc-max-wal-size"/>. Загружая большие объёмы данных, <productname>&productname;</productname> вынужден увеличивать частоту контрольных точек по сравнению с обычной (которая задаётся параметром <varname>checkpoint_timeout</varname>), а значит и чаще сбрасывать &laquo;грязные&raquo; страницы на диск. Временно увеличив <varname>max_wal_size</varname>, можно уменьшить частоту контрольных точек и связанных с ними операций ввода-вывода.</para>
  </sect2>

  <sect2 id="populate-pitr">
   <title>Отключите архивацию WAL и потоковую репликацию</title>

   <para>Для загрузки больших объёмов данных в среде, где используется архивация WAL или потоковая репликация, быстрее будет сделать копию базы данных после загрузки данных, чем обрабатывать множество операций изменений в WAL. Чтобы отключить передачу изменений через WAL в процессе загрузки, отключите архивацию и потоковую репликацию, назначьте параметру <xref linkend="guc-wal-level"/> значение <literal>minimal</literal>, <xref linkend="guc-archive-mode"/> &mdash; <literal>off</literal>, а <xref linkend="guc-max-wal-senders"/> &mdash; 0. Но имейте в виду, что изменённые параметры вступят в силу только после перезапуска сервера.</para>

   <para>Это не только поможет сэкономить время архивации и передачи WAL, но и непосредственно ускорит некоторые команды, которые могут вовсе не использовать WAL, если <varname>wal_level</varname> равен <literal>minimal</literal>. (Они могут гарантировать безопасность при сбое, не записывая все изменения в WAL, а выполнив только <function>fsync</function> в конце операции, что будет гораздо дешевле.) Это относится к следующим командам: <itemizedlist>
     <listitem>
      <para>
       <command>CREATE TABLE AS SELECT</command>
      </para>
     </listitem>
     <listitem>
      <para><command>CREATE INDEX</command> (и подобные команды, как например <command>ALTER TABLE ADD PRIMARY KEY</command>)</para>
     </listitem>
     <listitem>
      <para>
       <command>ALTER TABLE SET TABLESPACE</command>
      </para>
     </listitem>
     <listitem>
      <para>
       <command>CLUSTER</command>
      </para>
     </listitem>
     <listitem>
      <para><command>COPY FROM</command>, когда целевая таблица была создана или опустошена ранее в той же транзакции</para>
     </listitem>
    </itemizedlist></para>
  </sect2>

  <sect2 id="populate-analyze">
   <title>Выполните в конце <command>ANALYZE</command></title>

   <para>Всякий раз, когда распределение данных в таблице значительно меняется, настоятельно рекомендуется выполнять <xref linkend="sql-analyze"/>. Эта рекомендация касается и загрузки в таблицу большого объёма данных. Выполнив <command>ANALYZE</command> (или <command>VACUUM ANALYZE</command>), вы тем самым обновите статистику по данной таблице для планировщика. Когда планировщик не имеет статистики или она не соответствует действительности, он не сможет правильно планировать запросы, что приведёт к снижению быстродействия при работе с соответствующими таблицами. Заметьте, что если включён демон автоочистки, он может запускать <command>ANALYZE</command> автоматически; подробнее об этом можно узнать в <xref remap="6" linkend="vacuum-for-statistics"/> и <xref remap="6" linkend="autovacuum"/>.</para>
  </sect2>

  <sect2 id="populate-pg-dump">
   <title>Несколько замечаний относительно <application>pg_dump</application></title>

   <para>В скриптах загрузки данных, которые генерирует <application>pg_dump</application>, автоматически учитываются некоторые, но не все из этих рекомендаций. Чтобы загрузить данные, которые выгрузил <application>pg_dump</application>, максимально быстро, вам нужно будет выполнить некоторые дополнительные действия вручную. (Заметьте, что эти замечания относятся только к <emphasis>восстановлению</emphasis> данных, но не к <emphasis>выгрузке</emphasis> их. Следующие рекомендации применимы вне зависимости от того, загружается ли архивный файл <application>pg_dump</application> в <application>psql</application> или в <application>pg_restore</application>.)</para>

   <para>По умолчанию <application>pg_dump</application> использует команду <command>COPY</command> и когда она выгружает полностью схему и данные, в сгенерированном скрипте она сначала предусмотрительно загружает данные, а потом создаёт индексы и внешние ключи. Так что в этом случае часть рекомендаций выполняется автоматически. Вам остаётся учесть только следующие: <itemizedlist>
     <listitem>
      <para>Установите подходящие (то есть превышающие обычные) значения для <varname>maintenance_work_mem</varname> и <varname>max_wal_size</varname>.</para>
     </listitem>
     <listitem>
      <para>Если вы используете архивацию WAL или потоковую репликацию, по возможности отключите их на время восстановления. Для этого перед загрузкой данных, присвойте параметру <varname>archive_mode</varname> значение <literal>off</literal>, <varname>wal_level</varname> &mdash; <literal>minimal</literal>, а <varname>max_wal_senders</varname> &mdash; 0. Закончив восстановление, верните их обычные значения и сделайте свежую базовую резервную копию.</para>
     </listitem>
     <listitem>
      <para>Поэкспериментируйте с режимами параллельного копирования и восстановления команд <application>pg_dump</application> и <application>pg_restore</application>, и подберите оптимальное число параллельных заданий. Параллельное копирование и восстановление данных, управляемое параметром <option>-j</option>, должно дать значительный выигрыш в скорости по сравнению с последовательным режимом.</para>
     </listitem>
     <listitem>
      <para>Если это возможно в вашей ситуации, восстановите все данные в рамках одной транзакции. Для этого передайте параметр <option>-1</option> или <option>--single-transaction</option> команде <application>psql</application> или <application>pg_restore</application>. Но учтите, что в этом режиме даже незначительная ошибка приведёт к откату всех изменений и часы восстановления будут потрачены зря. В зависимости от того, насколько взаимосвязаны данные, предпочтительнее может быть вычистить их вручную. Команды <command>COPY</command> будут работать максимально быстро, когда они выполняются в одной транзакции и архивация WAL выключена.</para>
     </listitem>
     <listitem>
      <para>Если на сервере баз данных установлено несколько процессоров, полезным может оказаться параметр <option>--jobs</option> команды <application>pg_restore</application>. С его помощью можно выполнить загрузку данных и создание индексов параллельно.</para>
     </listitem>
     <listitem>
      <para>После загрузки данных запустите <command>ANALYZE</command>.</para>
     </listitem>
    </itemizedlist></para>

   <para>При выгрузке данных без схемы тоже используется команда <command>COPY</command>, но индексы, как обычно и внешние ключи, при этом не удаляются и не пересоздаются. <footnote>
      <para>Вы можете отключить внешние ключи, используя параметр <option>--disable-triggers</option> &mdash; но при этом нужно понимать, что тем самым вы не просто отложите, а полностью выключите соответствующие проверки, что позволит вставить недопустимые данные.</para>
     </footnote> Поэтому, загружая только данные, вы сами должны решить, нужно ли для ускорения загрузки удалять и пересоздавать индексы и внешние ключи. При этом будет так же полезно увеличить параметр <varname>max_wal_size</varname>, но не <varname>maintenance_work_mem</varname>; его стоит менять, только если вы впоследствии пересоздаёте индексы и внешние ключи вручную. И не забудьте выполнить <command>ANALYZE</command> после; подробнее об этом можно узнать в <xref remap="6" linkend="vacuum-for-statistics"/> и <xref remap="6" linkend="autovacuum"/>.</para>
  </sect2>
  </sect1>

  <sect1 id="non-durability">
   <title>Оптимизация, угрожающая стабильности</title>

   <indexterm zone="non-durability"><primary>угроза стабильности</primary></indexterm>

   <para>Стабильность &mdash; это свойство базы данных, гарантирующее, что результат зафиксированных транзакций будет сохранён даже в случае сбоя сервера или отключения питания. Однако обеспечивается стабильность за счёт значительной дополнительной нагрузки. Поэтому, если вы можете отказаться от такой гарантии, <productname>&productname;</productname> можно ускорить ещё больше, применив следующие методы оптимизации. Кроме явно описанных исключений, даже с такими изменениями конфигурации при сбое программного ядра СУБД гарантия стабильности сохраняется; риск потери или разрушения данных возможен только в случае внезапной остановки операционной системы. <itemizedlist>
     <listitem>
      <para>Поместите каталог данных кластера БД в файловую систему, размещённую в памяти (т. е. в <acronym>RAM</acronym>-диск). Так вы исключите всю активность ввода/вывода, связанную с базой данных, если только размер базы данных не превышает объём свободной памяти (возможно, с учётом файла подкачки).</para>
     </listitem>

     <listitem>
      <para>Выключите <xref linkend="guc-fsync"/>; сбрасывать данные на диск не нужно.</para>
     </listitem>

     <listitem>
      <para>Выключите <xref linkend="guc-synchronous-commit"/>; нет необходимости принудительно записывать <acronym>WAL</acronym> на диск при фиксации каждой транзакции. Но учтите, это может привести к потере транзакций (хотя данные останутся согласованными) в случае сбоя <emphasis>базы данных</emphasis>.</para>
     </listitem>

     <listitem>
      <para>Выключите <xref linkend="guc-full-page-writes"/>; защита от частичной записи страниц не нужна.</para>
     </listitem>

     <listitem>
      <para>Увеличьте <xref linkend="guc-max-wal-size"/> и <xref linkend="guc-checkpoint-timeout"/>; это уменьшит частоту контрольных точек, хотя объём <filename>/pg_xlog</filename> при этом вырастет.</para>
     </listitem>

     <listitem>
      <para>Создавайте <link linkend="sql-createtable-unlogged">нежурналируемые таблицы</link> для оптимизации записи в <acronym>WAL</acronym> (но учтите, что такие таблицы не защищены от сбоя).</para>
     </listitem>

    </itemizedlist></para>
  </sect1>

 </chapter>
